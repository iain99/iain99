[["index.html", "S1Z Lab 1 Welcome to S1Z Lab 1 tidyverse packages", " S1Z Lab 1 Welcome to S1Z Lab 1 In this lab, we will investigate the ways in which the statistics from a random sample can serve to make inference and test hypotheses about the true parameter in the larger population. We will explore here inference methods for numerical data. Before we begin however, let's revisit the difference between categorical and numerical data. Categorical Data = Data where an observation can belong to one of a certain fixed number of categories or groups. For example, someone's bloodtype. Your bloodtype can be one of A, B, AB or O. Numerical Data = Data in the form of numbers; rather than being defined as a member of some group or category. It also must make sense for calculations to be performed on those numbers, such as adding them or taking averages of them. This is important, for example a phone number is a number but it doesn't make sense to add phone numbers together. An example of numerical data is your height. It's measured with a number you can perform calculations directly on such as averages. Another example would be a count of the number of patients seen at a GP Surgery in a day. The material within this lab has been based on OpenIntro Chapter 7. Feel free to refer back to the materials to help you within this lab. tidyverse packages These labs use packages from the tidyverse suite of packages, which has been called \"the most powerful collection of R Packages for data science\". You don't need to go into much depth for these labs, but if you were interested, this intro is a good place to start. Aside: A package in R is just a collection of functions, data, documentation and compiled code that people have created to easily access and share with others. To run the code that appears in the consoles in this lab in your own version of RStudio, start by installing and loading these packages. install.packages(&quot;tidyverse&quot;) install.packages(&quot;infer&quot;) install.packages(&quot;openintro&quot;) library(tidyverse) library(infer) library(openintro) Credit where credit is due The labs in S1Y/Z are a derivative of the labs on the OpenIntro Statistics website by the OpenIntro team used under a Creative Commons Attribution-ShareAlike 4.0 International License. Some of the artwork used is by @allison_horst "],["introducing-the-data.html", "Introducing The Data", " Introducing The Data In this lab, we will explore and visualise the data using the tidyverse suite of packages and perform statistical inference. We will be looking at data from the Youth Risk Behaviour Surveillance System (YRBSS) survey, which uses data from American high school students to help discover health patterns. The data frame is called yrbss and is part of the openintro package should you wish to look at it yourself. It contains 13 variables: • age : Age of the student. • gender : Gender of the student. • grade : School grade of the student. • hispanic : If the student is hispanic, or not. • race : Ethnicity of the student • height : Height of the student, in metres. • weight : Weight of the student, in kilograms. • helmet_12m : How often the student wore a helmet while riding a bike in the last 12 months. • text_while_driving_30d : How many days out of the last 30 did the the student text while driving. • physically_active_7d : How many days out of the last 7 was the student physically active for at least an hour. • hours_tv_per_school_day : How many hours of TV does the student typically watch on a school night. • strength_training_7d : How many days out of the last 7 did the student lift weights. • school_night_hours_sleep : How many hours of sleep does the student typically get on a school night? First of all, it is always a good idea to look at the dataset you are working with to get a good sense of what it looks like, and the different types of data you may have, e.g. categorical or numerical. Copy and run the code below to look at the first 6 rows of data and the structure of it. Recall from Lab 0 in S1Y that head() is a function where you put in it's brackets the name of the data frame, in this case yrbss, and it gives you the first 6 lines of that data to look at. You can press the arrows to go along and see all the variables. Again recall from S1Y Lab 0 str() is another function again where you put the name of the data frame in the brackets, and this time it gives you the number of observations and the number of variables you have, the types of those variables e.g. \"int\" for an integer, \"num\" for a number and \"chr\" for a string of characters, as well as the first few values of each variable. head(yrbss) str(yrbss) How many observations/rows are there in the entire data set? Hint Look again at the result of the str() function. "],["inference-for-numerical-data.html", "Inference for Numerical Data", " Inference for Numerical Data Using the data from the YRBSS survey, we will now analyze the weight of the students in kilograms, stored in the weight variable in the YRBSS data frame. Please note that for the next section our data set is called YRBSS, the capital letters are important, we will go back to yrbss afterwards though We can obtain the summary statistics of the variable by running the following code: summary(YRBSS$weight) To visualise the distribution of the weights, you may want to produce a box-plot for the weight variable by running the following code: ggplot(data = YRBSS, mapping = aes(y = weight)) + geom_boxplot() Exercise 1 Another way of visualising the distribution of a variable is to look at the histogram of the data. Write code to produce a histogram for the weight variable. Hint We want to use the function ggplot(), specifying the data argument and the variable to go along the \\(x\\)-axis. Use geom_histogram() to produce a histogram. Solution ggplot(data = YRBSS, aes(x = weight)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. How would you describe the distribution of the weights of the students? The weights of the students appear fairly normally distributed, but are a little left skewed i.e. have a long tail on the left of the histogram. The weights do not actually appear very normally distributed, and probably follow some other distribution. The weights are perfectly normally distributed. The weights of the students appear fairly normally distributed, but are a little right-skewed i.e. have a reasonably long tail on the right of the histogram. Hint Look carefully at the shape of the graph, particularly towards the right. To find how many observations we are missing from the weight variable you can run the following R code: sum(is.na(YRBSS$weight)) The is.na() function creates a vector that corresponds to the variable provided, (weight in this instance, from our dataset YRBSS) with TRUE for a missing value and FALSE for a non-missing value. The sum() function then adds up the elements in this created vector such that TRUE is equivalent to 1 and FALSE is equivalent to 0 and hence the sum of this vector is equivalent to the number of TRUE entries which calculates how many of these \"NA\" values there are. How many observations are we missing heights from? You will find the previous example useful. Hint Use the function sum(is.na(YRBSS$...)). Please note that for the remaining sections our data set is called yrbss again Next, consider the possible relationship between a high schooler's weight and their physical activity. Plotting the data is a useful first step because it helps us quickly visualise trends, identify strong associations and develop research questions. First, we will create a new variable physical_3plus, which will be coded as either \"yes\" if they are physically active for at least 3 days a week, and \"no\" if not, using the mutate() function. yrbss &lt;- yrbss %&gt;% mutate(physical_3plus = ifelse(yrbss$physically_active_7d &gt; 2, &quot;yes&quot;, &quot;no&quot;)) Look at the code below that creates a boxplot. If you wanted to add another dimension to the boxplot, say, splitting it by some other variable, you would want to add an x = argument inside the aes bracket, making sure there's a comma between it and the y = weight part. Some variable name would follow the x =. ggplot(data = yrbss, mapping = aes(y = weight)) + geom_boxplot() Exercise 2 Make a side-by-side boxplot of physical_3plus and weight i.e. a boxplot with the physical_3plus variable on the x axis and the weight variable on the y axis. This will show side by side the boxplots of weights, comparing between the yes and no for physical_3plus. Hint With the aes() argument you want to specify that x = physical_3plus. Solution ggplot(data = yrbss, aes(x = physical_3plus, y = weight)) + geom_boxplot() What could you interpret from this graph? The median weight appears to be significantly higher for those that are not physically active 3+ days a week. Those that are physically active 3+ days a week on average weigh significantly more. The mean weight appears to be significantly higher for those that are physically active 3+ days a week. The median weight appears to be significantly higher for those that are physically active 3+ days a week. Hint This is just an initial impression, so we don't decide anything for certain yet until we've done some analysis. The box plots show how the medians of the two distributions compare, but we can also compare the means of the distributions using the same procedure that we used back in Exercise 1, except our summary this time is a mean rather than a count. Run the code below to see the mean weights of the students, separated by \"yes\" they are physically active 3+ days a week or \"no\" they aren't. yrbss %&gt;% group_by(physical_3plus) %&gt;% summarise(mean_weight = mean(weight, na.rm = TRUE)) There is an observed difference, but is this difference statistically significant? In order to answer this question we will conduct a hypothesis test. "],["inference-on-means.html", "Inference on Means Conditions for Inference, or, a Normality Check Confidence Interval", " Inference on Means Conditions for Inference, or, a Normality Check As seen on the bottom of OpenIntro Page 251 two conditions are required for making inference on numerical variables: Independence: The sample observations must be independent. The most common way to satisfy this condition is when the sample is a simple random sample from the population. Normality: When a sample is small, we also require that the sample observations come from a normally distributed population. We can relax this condition more and more for larger and larger sample sizes. This condition is obviously vague, making it difficult to evaluate, so next we introduce a couple rules of thumb to make checking this condition easier. \\(n &lt; 30:\\) If the sample size n is less than 30 and there are no clear outliers in the data, then we typically assume the data come from a normal enough distribution to satisfy the condition. \\(n \\geq 30:\\) If the sample size n is at least 30 and there are no particularly extreme outliers, then we typically assume adequate normality. Exercise 3 Are all conditions necessary for inference satisfied for our data? Is the independence condition satisfied? Yes No Hint Consider the structure of the data i.e. The collection of students. In general, are the students independent of one another? Both the sample size and the distribution of the boxplots would help us verify normality. Compute the sizes of the two groups, (yes/no for the physical_3plus variable) by using the summarise() function. Also recreate the boxplot of physical_3plus and weight from Exercise 2 to check the normality assumption. Hint To count the group sizes, you first want to group_by the variable physical_3plus, and then count the number of observations, n(), there are in each group. To make the boxplot, physical_3plus should be along the \\(x\\)-axis and weight should be along the \\(y\\)-axis. Solution yrbss %&gt;% group_by(physical_3plus) %&gt;% summarise(count = n()) ## # A tibble: 2 x 2 ## physical_3plus count ## &lt;chr&gt; &lt;int&gt; ## 1 no 2656 ## 2 yes 5695 ggplot(yrbss, aes(y = weight, x = physical_3plus)) + geom_boxplot() Is the normality condition satisfied? Yes No Hint Consider the size of the two groups and whether any outliers are extreme. Exercise 4 Since the assumptions of independence and normality are both satisfied, we can proceed with making inference, and hence construct confidence intervals or perform a hypothesis test about the weight variable for those who exercise at least three times a week and those who don't. Let \\[\\mu_l = \\textrm{Average weight of a student who is physically active less than 3 days a week}\\] and \\[\\mu_m = \\textrm{Average weight of a student who is physically active 3 or more days a week}\\] What are the null and alternative hypotheses for testing if the average weights are different for those who exercise at least three times a week and those who don’t? \\(H_0: \\mu_l = \\mu_m , H_1: \\mu_l &gt; \\mu_m\\) \\(H_0: \\mu_l = \\mu_m , H_1: \\mu_l &lt; \\mu_m\\) \\(H_0: \\mu_l \\ne \\mu_m , H_1: \\mu_l = \\mu_m\\) \\(H_0: \\mu_l = \\mu_m , H_1: \\mu_l \\ne \\mu_m\\) Hint The only question you can answer is whether there is a statistically significant difference between the two average weights. You can't test at the moment how different they are. Confidence Interval Next, we will be conducting a hypothesis test, and ultimately a confidence interval, for a difference of two means. Namely, the mean weights in the two groups (those that are active 3+ days a week and the other group that aren't). More details on this can be found on page 267 of the OpenIntro textbook. In general, we have some sort of \\[\\textrm{Statistic} \\pm \\textrm{Percentile of a distribution}*\\textrm{Standard Error}\\] More specifically, we have the following: \\[(\\mu_1 - \\mu_2) \\pm t^* \\times \\textrm{SE}\\] So our new statistic is \\((\\mu_1 - \\mu_2)\\), the difference in averages between the two groups, our new percentile is \\(t^*\\), from something called the t-distribution rather than the standard Normal distribution. The standard error \\(\\textrm{SE}\\) now equals \\[\\textrm{SE} = \\sqrt{\\frac{\\sigma_1^2}{n_1}+\\frac{\\sigma_2^2}{n_2}}\\] where \\(n_1\\), \\(n_2\\) are the sample sizes of the two groups you're considering and \\(\\sigma_1^2\\), \\(\\sigma_2^2\\) are the variances of the two groups. Putting it all together, our confidence interval for the difference in means between two groups is: \\[(\\mu_1 - \\mu_2) \\pm t^* \\times \\sqrt{\\frac{\\sigma_1^2}{n_1}+\\frac{\\sigma_2^2}{n_2}}\\] We first calculate \\((\\mu_1 - \\mu_2)\\), which we will save as obs_diff. This is the difference in the two means of the weights of the two groups of students; one that is active 3+ days a week and the other group that isn't. Namely we are taking group 1 to be \"yes\" active 3+ days a week and group 2 to be \"no\" not active 3+ days a week. yes &lt;- yrbss %&gt;% filter(physical_3plus == &quot;yes&quot;) no &lt;- yrbss %&gt;% filter(physical_3plus == &quot;no&quot;) mu1 &lt;- mean(yes$weight) mu2 &lt;- mean(no$weight) obs_diff &lt;- (mu1 - mu2) Now recall our calculation from Exercise 3 to get our \\(n_1\\) and \\(n_2\\) i.e. the sizes of the two groups, remembering that \"yes\" means group 1 and \"no\" means group 2. yrbss %&gt;% group_by(physical_3plus) %&gt;% summarise(count = n()) ## # A tibble: 2 x 2 ## physical_3plus count ## &lt;chr&gt; &lt;int&gt; ## 1 no 2656 ## 2 yes 5695 n1 &lt;- 5695 n2 &lt;- 2656 Next, our \\(t^*\\) value. As it happens, (due to a rigorously proved and fascinating result in Statistics), for sufficiently large n, the t-distribution tends toward the normal distribution. As in, when your sample size is big enough the t distribution is basically identical to the standard normal distribution. Therefore, since the samples we have are so large, our \\(t^*\\) value this time is also 1.96 for a 95% confidence interval. Make sure you always check though, because you often will have a smaller sample and therefore your \\(t^*\\) will be different! t.star &lt;- 1.96 Now we will get the variances of the two groups. sigma_squared_1 &lt;- var(yes$weight) sigma_squared_2 &lt;- var(no$weight) Finally, let's put it all together and get our confidence interval! standard.error &lt;- sqrt((sigma_squared_1/n1) + (sigma_squared_2/n2)) lower.bound &lt;- obs_diff - t.star*standard.error upper.bound &lt;- obs_diff + t.star*standard.error c(lower.bound, upper.bound) ## [1] 0.7215522 2.3338998 Note It is equivalent to slightly re-arrange the above null and alternative hypotheses, that is we consider the difference between two means such that: \\[H_0: \\mu_l - \\mu_m = 0\\] \\[H_1: \\mu_l - \\mu_m \\ne 0\\] Namely there is no difference between the average weights of the two groups of students, or there is a difference in average weights between the two groups. Notice this is just a rearranging of the equation. Looking at the confidence interval, what do you conclude? Since the CI does not contain 0, we fail to reject the null hypothesis i.e. conclude that there is no statistically significant difference in the mean weights of students who are and aren't physcially active 3+ days a week. Since the CI does not contain 0, we reject the null hypothesis in favour of the alternative i.e. We conclude there is a statistically significant difference in the mean weights of students who are and aren't physcially active 3+ days a week. Since the CI contains 0, we fail to reject the null hypothesis i.e. conclude that there is a statistically significant difference in the mean weights of students who are and aren't physcially active 3+ days a week. Since the obs. dif. value is outside of the CI, we fail to reject the null hypothesis i.e. We conclude there is no statistically significant difference in the mean weights of students who are and aren't physcially active 3+ days a week. Hint Consider whether the interval contains a certain vital number. "],["group-tasks.html", "Group Tasks Pregnancies Questions", " Group Tasks The group tasks in this lab will not be assessed, however they do offer good practise into writing your own code in R. Pregnancies Questions In 2004, the state of North Carolina released a large data set containing information on births recorded in this state. This data set is useful to researchers studying the relation between habits and practices of expectant mothers and the birth of their children. We will work with a random sample of observations from this data set. Load the nc data set into your workspace by typing the following code in an Rscript file in your local Rstudio. download.file(&quot;http://www.openintro.org/stat/data/nc.RData&quot;, destfile = &quot;nc.RData&quot;) load(&quot;nc.RData&quot;) Before attempting the following exercises, explore the data as much or as little as you like using code from this Lab. Task 1 Calculate a 95% confidence interval for the average length of pregnancies (weeks). Note that since you’re doing inference on a single population parameter, there is no explanatory variable. Complete the following sentence, giving your answers to 2 decimal places. We are 95% certain that the average length of pregnancy for the population of women is between and weeks. Task 2 Calculate a new confidence interval for the same parameter at the 90% confidence level. Complete the following sentence, giving your answers to 2 decimal places. We are 90% certain that the average length of pregnancy for the population of women is between and weeks. Task 3 Conduct a hypothesis test evaluating whether the average weight gained by younger mothers is different than the average weight gained by mature mothers. Hint Create a 95% confidence interval for the difference in mean weight gained between the two age groups. Don't forget to calculate a new standard error to use. What are your conclusions from this hypothesis test? Given that the confidence interval contains 0, we reject the null hypothesis and conclude that there is a statistically significant difference in weight gained between younger and mature mothers in the population. Given that the confidence interval does not contain 0, we reject the null hypothesis and conclude that there is a statistically significant difference in weight gained between younger and mature mothers in the population. Given that the confidence interval does not contain 0, we do not reject the null hypothesis and conclude that there is no statistically significant difference in weight gained between younger and mature mothers in the population. Given that the confidence interval contains 0, we do not reject the null hypothesis and conclude that there is no statistically significant difference in weight gained between younger and mature mothers in the population. Task 4 Create side-by-side boxplots of the mothers' age (mage) for the two group; \"mature mom\" and \"younger mom\". Based on these boxplots, what would you say the age cutoff for a mother to be classified as a \"younger mom\" is? 25 30 35 40 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
